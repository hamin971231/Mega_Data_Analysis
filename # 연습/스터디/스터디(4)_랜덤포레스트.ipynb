{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 의사결정나무와 랜덤포레스트( 예측 / 분류 모델 )\n",
    "## 13.3 의사결정나무와 랜덤포레스트( 예측 / 분류 모델 )\n",
    "\n",
    "> 뒤집어 놓은 나무와 같은 모양. 가지가 나눠지는 부분이 독립변수의 조건, 마지막 잎사귀들은 종속변수를 나타냄\n",
    "\n",
    "### 13.3.1 분류나무와 회귀나무\n",
    "- 의사결정나무는 명목형 종속변수를 분류할 수 있는 분류나무와 연속형 종속변수를 예측할 수 있는 회귀나무로 나뉜다.\n",
    "\n",
    "#### 분류나무\n",
    "- 분류나무는 기본적으로 데이터를 얼마나 잘 분류했는지 알 수 있는 척도인 불순도를 낮추고 순도를 높이는 방향으로 분류기준을 찾아낸다. 즉 한 노드내에서는 범주의 동질성이 높고, 노드 간에는 이질성이 최대한 높도록 만들어주는 것이다. \n",
    "\n",
    "- 데이터의 불순도를 나타내는 대표적인 기준은 지니계수와 엔트로\n",
    "- 분류를 통해 지니 계수나 엔트로피가 증가 혹은 감소한 양을 정보 획득량이라고 부른다. \n",
    "<20명에 대한 지니계수>\n",
    "![Alt text](image-2.png)\n",
    "\n",
    "<45세 연령기준으로 첫번째 분류>\n",
    "![Alt text](image-3.png)\n",
    "\n",
    "> 20명에 대한 지니계수에서 집단에 따른 지니계수 빼주면 된다. \n",
    "> 하지만 집단이 많을수록 지니계수가 너무 커지게 되므로 가중치를 부여해준다.\n",
    "![Alt text](image-4.png)\n",
    "\n",
    "\n",
    "- 엔트로피는 지니 계수와 비슷하지만 이진 로그를 취함으로써 정규화 과정을 거치게 되고, 값의 범위는 0~1을 갖게된다. \n",
    "\n",
    "- 엔트로피 공식\n",
    "\n",
    "![Alt text](image-5.png)\n",
    "\n",
    "![Alt text](image-6.png)\n",
    "- 엔트로피의 정보 획득량도 지니계수와 마찬가지로 데이터 비율의 가중치를 주어 구할 수 있다. \n",
    "\n",
    "- 분류나무는 각 독립변수의 수치마다 지니 계수나 엔트로피 값을 구해서 최적의 정보 획득량을 얻을 수 있는 기준으로 분류를 해 나가는 것\n",
    "- 1회 자식노드를 만들기 위해서 변수가 k개 , 관측치가 n개라고 했을 때 k(n-1)번 계산하고, 정보 획득량이 없을 때까지 가지를 뻗어나감. \n",
    "\n",
    "- 의자결정 나무의 종류\n",
    "\n",
    "![Alt text](image-7.png)\n",
    "\n",
    "#### 회귀나무\n",
    "\n",
    "- 회구나무는 종속변수가 연속형 변수이기 떄문에 잔차 제곱합 등의 분류 기준을 사용한다.\n",
    "- 회귀나무는 종속변수의 비선형성에 영향을 받지 않기 떄문에 일반 선형회귀분석에 비해 모델활용이 까다롭지않다.\n",
    "> 회귀나무에서 각 잎 노드에서 종속변수의 예측은 해당 노드 내의 데이터 포인트의 평균값으로 계산된다. 이로써 각 잎 노드마다 다른수준의 종속변수 값을 예측할 수 있으며 이는 비선형성을 잡아낼수 있는 특징임. 즉 각각의 잎 노드에서 종속변수의 다른 수준을 예측하기 때문에 선형적이라고 말할 수 없음.\n",
    "\n",
    "![Alt text](image-8.png)\n",
    "\n",
    "- 회귀나무는 끝 노드에 속한 데이터 값의 평균을 구해 회귀 예측값을 계산한다. --> 비선형적임.\n",
    "\n",
    "- 회귀나무는 그 밖에 F값이나 분산의 감소량을 분류 기준으로 사용한다.\n",
    "- F값이 크다는것 = 노드 간의 이질성이 높다는 것을 의미함. \n",
    "- 분산의 감소량의 경우, 한 노드에 속한 관측치 값들의 분산이 작아진다는 것은 동질성이 높다는 것을 의미한다. \n",
    "\n",
    "### 13.3.2 의사결정나무 모델의 장단점\n",
    "#### 장점\n",
    "- 의사결정나무 모델은 비선형 모델이기 때문에 회귀분석과 같이 데이터의 선형성, 정규성, 등분산성 등이 필요하지 않다. \n",
    "\n",
    "#### 단점\n",
    "- 의사결정나무와 일반 회귀 모델의 경우 명목형 변수는 예측 데이터에 있는 정보가 학습데이터에 없으면 예측이 불가능\n",
    "- 의사결정나무는 학습데이터에 있는 연속형 변수의 값만큼만 예측데이터에 적용되기 떄문에, 예측할 수 있는 종속변수의 최소 최댓값은 학습 데이터의 범위에 한정된다.\n",
    "\n",
    "> 따라서 학습데이터와 예측데이터의 연속형 변수값 편차가 큰경우에는 예측력이 떨어질 수 있음.\n",
    "\n",
    "- 학습 데이터에 과적합 될 확률이 높다. \n",
    "\n",
    "### 13.3.3 의사결정나무 모델의 과적합 방지를 위한 방법\n",
    "\n",
    "\n",
    "- 과적합을 방지하기 위해 가지치기, 정보획득량 임곗값 설정, 한 노드에 들어가는 최소 데이터 수 제한하기, 노드의 최대 깊이 제한하기 등이 있다. \n",
    "\n",
    "#### 가지치기\n",
    "- 가지치기 : 모델의 분기 가지들을 적절히 쳐내 과도하게 세밀하게 분기된 부분들을 없애준다. 이는 버리는것이 아니라, 분기를 합치는 개념.\n",
    "\n",
    "- 가지치기의 기준 : 분기 가지가 많아질수록 학습데이터의 오분류율은 낮아지게 되고, 특정수준 이상이 되면 검증 데이터의 오분류율은 높아지는 원리는 이용함.\n",
    "\n",
    "![Alt text](image-9.png)\n",
    "\n",
    "> 학습데이터로 만들어진 나무 모델응ㄹ 검증데이터에 반영하여, 오분류율을 확인한다. 끝단 가지들을 조금씩 쳐내가면서 검증데이터의 오분류율이 최소가 되는 시점까지 가지치기를 실시. --> 학습데이터의 모델정확도는 다소 떨어지더라도, 과적합을 방지하여 모델을 일반화할 수 있다.\n",
    "\n",
    "#### 정보 획득량 임곗값 설정\n",
    "- 분기를 했을 때 정보 획득량이 너무 적으면 분기를 멈추도록 설정하는것이다.\n",
    "- 한 노드에 들어가는 최소 데이터 수를 제한하는 방법과\n",
    "- 임계값은 노드를 분할하는 데 필요한 정보 획득량의 최소 기준을 정의 정보 획득량이 임곗값보다 낮은 분할은 수행되지 않고 노드의 분할이 중단\n",
    "\n",
    "#### 노드의 최대 깊이 제한\n",
    "- 노드의 최대깊이를 제한하는 방법 역시 가지가 너무 세세하게 분리되는것을 방지해 주기 떄문에 일반화된 의사결정나무 모델을 만들 떄 많이 쓰인다.\n",
    "- 노드의 최대 깊이를 제한하면 모델의 복잡성을 줄이고 과적합을 방지할 수 잇다. -> 특정 깊이 제한을 설정하면 트리가 특정 깊이에 도달할 때, 더이상 분할하지 않고 종료\n",
    "- 너무 작게 설정하면 과소적합일어남.\n",
    "\n",
    "420\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.3.4 랜덤포레스트\n",
    "\n",
    "학습 성능의 변동이 크다는 고질적인 문제를 보완하기 위해 나온 모델이 랜덤 포레스트임. \n",
    "\n",
    "나무를 여러 개 만들어서 학습을 하는것 인데, 나무 여러 개를 만들어 학습을 하게 되면 다양한 상황을 고려하여 학습하기 때문ㅔ 과적합을 방지할 수 잇따.\n",
    "\n",
    "![Alt text](image-10.png)\n",
    "\n",
    "- 부트스트랩 \n",
    ": 부트스트랩은 하나의 데이터 셋을 중복을 허용하여 무작위로 여러 번 추출하는 것이다.\n",
    "\n",
    ": 부트스트랩은 신뢰구간에 대한 통계적 추정의 정확도를 높이는 데 사용하는 유용한 방법.\n",
    "\n",
    ": 랜덤 포레스트에서 무작위로 선택할 독립변수의 수는 일반적으로 전체 독립변수 개수의 제곱근으로 한다. \n",
    "\n",
    "![Alt text](image-11.png)\n",
    "\n",
    "- 배깅 \n",
    ": 여러 개의 의사결정 나무를 하나의 모델로 결합해 주는 것\n",
    "\n",
    ": 분류 모델의 경우 투표 방식으로 집계하여 연속형 값의 예측모델인 경우 평균으로 집계한다.\n",
    "\n",
    ": "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 필요한 패키지 임포트\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pydotplus\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.core.display import Image\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('glass.csv')\n",
    "df.head()\n",
    "###각 유리의 종류를 의미하는 type이랑 원재료 함량에 대한 정보\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 214 entries, 0 to 213\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   RI      214 non-null    float64\n",
      " 1   Na      214 non-null    float64\n",
      " 2   Mg      214 non-null    float64\n",
      " 3   Al      214 non-null    float64\n",
      " 4   Si      214 non-null    float64\n",
      " 5   K       214 non-null    float64\n",
      " 6   Ca      214 non-null    float64\n",
      " 7   Ba      214 non-null    float64\n",
      " 8   Fe      214 non-null    float64\n",
      " 9   Type    214 non-null    int64  \n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 16.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 5, 6, 7], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "      <th>Type_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type Type_str\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1        1\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1        1\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1        1\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1        1\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1        1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Type 칼럼 문자형 변환\n",
    "df['Type_str'] = df['Type'].apply(str)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'Type',\n",
       "       'Type_str'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data length :  128\n",
      "test data length :  86\n"
     ]
    }
   ],
   "source": [
    "### 의사결정나무 모델용 데이터셋 가공\n",
    "\n",
    "### 독립변수, 종속변수 분리\n",
    "df_x = df[['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe'\n",
    "       ]]\n",
    "df_y = df[['Type_str']]\n",
    "\n",
    "x_train, x_test,y_train,y_test = train_test_split(df_x,df_y,test_size=0.4,random_state=324)\n",
    "\n",
    "## 학습셋, 검증셋 확인\n",
    "print('train data length : ',len(x_train))\n",
    "print('test data length : ',len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.627906976744186\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 의사결정 모델 적용\n",
    "# 모델 생성 및 학습\n",
    "\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=56)\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "y_train_pred = model.predict(x_train)\n",
    "# 정확도 계산 \n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(accuracy_score(y_train,y_train_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 의사결정나무 파라미터\n",
    "1. criterion:\n",
    "\n",
    "- 엔트로피(entropy) 또는 지니 계수(gini) 중 하나를 선택합니다.\n",
    "- 노드 분할 시 사용되는 지표를 지정합니다.\n",
    "- 기본값은 'gini'이며, 'entropy'로 설정할 수도 있습니다.\n",
    "\n",
    "2. max_depth:\n",
    "\n",
    "- 트리의 최대 깊이를 제한합니다.\n",
    "- 과적합(overfitting)을 방지하기 위해 사용됩니다.\n",
    "- 트리의 최대 깊이를 지정하거나 None으로 설정하여 제한을 두지 않을 수 있습니다.\n",
    "\n",
    "3. min_samples_split:\n",
    "\n",
    "- 노드를 분할하기 위한 최소 샘플 수를 지정합니다.\n",
    "- 이 값보다 적은 수의 샘플이 노드에 있으면 더 이상 분할하지 않습니다.\n",
    "\n",
    "4. min_samples_leaf:\n",
    "\n",
    "- 리프 노드(말단 노드)에 있어야 하는 최소 샘플 수를 지정합니다.\n",
    "- 이 값보다 적은 수의 샘플이 있는 리프 노드는 더 이상 분할하지 않습니다.\n",
    "\n",
    "5. max_features:\n",
    "\n",
    "- 각 노드에서 분할에 사용될 최대 특성(속성) 수를 지정합니다.\n",
    "- 과적합을 제어하기 위해 사용됩니다.\n",
    "- 정수 값 또는 비율(예: 'sqrt', 'log2')로 설정할 수 있습니다.\n",
    "- max_features에서 'auto'는 무작위 포레스트(Random Forest)에서 사용될 때의 설정입니다. 'auto'를 사용하면 무작위 포레스트는 각 분할할 때 고려할 최대 특성(또는 속성)의 수를 자동으로 설정합니다.  보통 독립변수의 제곱근\n",
    "\n",
    "6. splitter:\n",
    "\n",
    "- 노드를 분할하는 데 사용되는 전략을 선택합니다.\n",
    "- 'best'는 최선의 분할을 찾으며 'random'은 무작위 분할을 사용합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그리드 서치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hamin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "6720 fits failed out of a total of 20160.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6720 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Hamin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Hamin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Hamin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Hamin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Hamin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [  nan   nan   nan ... 0.476 0.64  0.476]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=56),\n",
       "             param_grid={&#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                         &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7, 9],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 3, 5, 7, 9, 11, 13],\n",
       "                         &#x27;min_samples_split&#x27;: [3, 5, 7, 9, 11, 13],\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=56),\n",
       "             param_grid={&#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                         &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7, 9],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 3, 5, 7, 9, 11, 13],\n",
       "                         &#x27;min_samples_split&#x27;: [3, 5, 7, 9, 11, 13],\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=56)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=56)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=56),\n",
       "             param_grid={'class_weight': ['balanced', None],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [3, 5, 7, 9],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'min_samples_leaf': [1, 3, 5, 7, 9, 11, 13],\n",
       "                         'min_samples_split': [3, 5, 7, 9, 11, 13],\n",
       "                         'splitter': ['best', 'random']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min_impurity_decrease : 최소불순도\n",
    "# min_impurity_split : 나무 성장을 멈추기 위한 임계치 \n",
    "grid_param =  {'criterion': ['gini', 'entropy'],\n",
    "              'max_depth': [3, 5, 7, 9],\n",
    "              'min_samples_split': [x for x in range(3, 15,2)],\n",
    "              'min_samples_leaf': [x for x in range(1, 15,2)],\n",
    "              'max_features': ['auto', 'sqrt', 'log2'],\n",
    "              'class_weight': ['balanced', None],\n",
    "              'splitter': ['best', 'random']}\n",
    "\n",
    "grid_model = GridSearchCV(model,grid_param, scoring='accuracy',cv= 5)\n",
    "grid_model.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "0.96875\n",
      "0.5930232558139535\n"
     ]
    }
   ],
   "source": [
    "print(grid_model.best_params_)\n",
    "\n",
    "dt = grid_model.best_estimator_\n",
    "print(dt.score(x_train,y_train))\n",
    "print(dt.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type_str\n",
       "1           31\n",
       "2           25\n",
       "7           13\n",
       "3            7\n",
       "5            6\n",
       "6            4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type_str\n",
       "2           51\n",
       "1           39\n",
       "7           16\n",
       "3           10\n",
       "5            7\n",
       "6            5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 음 근데 y_test랑, y_train의 데이터가 좀 이상한거같음. train은 2가 제일 많은데 test는 1이 제일 많음. >> 데이터 불균형 같음.\n",
    "\n",
    "> 그래서 정확도 차이가 나는거 같음 >> 새로운 샘플링 방식이 필요한거같음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 훈련데이터의 정확도가 높은 반면 검증데이터에 대한 성능이 부족함. \n",
    "\n",
    "해결방법\n",
    "1. 모델복잡도 줄이는 것 (예 : 의사결정 트리의 깊이를 제한)\n",
    "2. 더 많은 훈련데이터 수집\n",
    "\n",
    "> 그래도 그리드서치로 최적화 ㄱㄱㄱ \n",
    "> 근데 왜 성능개선 안되는거임; \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RI</td>\n",
       "      <td>0.160438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Na</td>\n",
       "      <td>0.079689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mg</td>\n",
       "      <td>0.176830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Al</td>\n",
       "      <td>0.179986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Si</td>\n",
       "      <td>0.080603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K</td>\n",
       "      <td>0.044855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ca</td>\n",
       "      <td>0.077160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ba</td>\n",
       "      <td>0.155002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fe</td>\n",
       "      <td>0.045436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature  importance\n",
       "0      RI    0.160438\n",
       "1      Na    0.079689\n",
       "2      Mg    0.176830\n",
       "3      Al    0.179986\n",
       "4      Si    0.080603\n",
       "5       K    0.044855\n",
       "6      Ca    0.077160\n",
       "7      Ba    0.155002\n",
       "8      Fe    0.045436"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 의사결정나무 변수 중요도 확인\n",
    "# 독립변수 중요도 확인 \n",
    "model.feature_importances_\n",
    "pd.DataFrame({\"feature\":x_train.columns,\n",
    "              'importance' : model.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "알류미늄 마그네슘이 중요함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.44/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "Program terminated with status: 1. stderr follows: Format: \"jpg\" not recognized. Use one of:\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Hamin\\Mega_Data_Analysis\\# 연습\\스터디\\스터디(4)_랜덤포레스트.ipynb 셀 26\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Hamin/Mega_Data_Analysis/%23%20%EC%97%B0%EC%8A%B5/%EC%8A%A4%ED%84%B0%EB%94%94/%EC%8A%A4%ED%84%B0%EB%94%94%284%29_%EB%9E%9C%EB%8D%A4%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8.ipynb#X34sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m dot_data\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Hamin/Mega_Data_Analysis/%23%20%EC%97%B0%EC%8A%B5/%EC%8A%A4%ED%84%B0%EB%94%94/%EC%8A%A4%ED%84%B0%EB%94%94%284%29_%EB%9E%9C%EB%8D%A4%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8.ipynb#X34sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m graph \u001b[39m=\u001b[39m pydotplus\u001b[39m.\u001b[39mgraph_from_dot_data(dot_data)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Hamin/Mega_Data_Analysis/%23%20%EC%97%B0%EC%8A%B5/%EC%8A%A4%ED%84%B0%EB%94%94/%EC%8A%A4%ED%84%B0%EB%94%94%284%29_%EB%9E%9C%EB%8D%A4%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8.ipynb#X34sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m Image(graph\u001b[39m.\u001b[39;49mcreate_jpg())\n",
      "File \u001b[1;32mc:\\Users\\Hamin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pydotplus\\graphviz.py:1797\u001b[0m, in \u001b[0;36mDot.__init__.<locals>.<lambda>\u001b[1;34m(f, prog)\u001b[0m\n\u001b[0;32m   1792\u001b[0m \u001b[39m# Automatically creates all the methods enabling the creation\u001b[39;00m\n\u001b[0;32m   1793\u001b[0m \u001b[39m# of output in any of the supported formats.\u001b[39;00m\n\u001b[0;32m   1794\u001b[0m \u001b[39mfor\u001b[39;00m frmt \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformats:\n\u001b[0;32m   1795\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(\n\u001b[0;32m   1796\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mcreate_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m frmt,\n\u001b[1;32m-> 1797\u001b[0m         \u001b[39mlambda\u001b[39;00m f\u001b[39m=\u001b[39mfrmt, prog\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprog: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate(\u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49mf, prog\u001b[39m=\u001b[39;49mprog)\n\u001b[0;32m   1798\u001b[0m     )\n\u001b[0;32m   1799\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mcreate_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m frmt]\n\u001b[0;32m   1800\u001b[0m     f\u001b[39m.\u001b[39m\u001b[39m__doc__\u001b[39m \u001b[39m=\u001b[39m (\n\u001b[0;32m   1801\u001b[0m \u001b[39m        \u001b[39m\u001b[39m'''Refer to the docstring accompanying the'''\u001b[39;00m\n\u001b[0;32m   1802\u001b[0m \u001b[39m        \u001b[39m\u001b[39m''''create' method for more information.'''\u001b[39;00m\n\u001b[0;32m   1803\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Hamin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pydotplus\\graphviz.py:2030\u001b[0m, in \u001b[0;36mDot.create\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   2027\u001b[0m status \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39mwait()\n\u001b[0;32m   2029\u001b[0m \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 2030\u001b[0m     \u001b[39mraise\u001b[39;00m InvocationException(\n\u001b[0;32m   2031\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mProgram terminated with status: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. stderr follows: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (\n\u001b[0;32m   2032\u001b[0m             status, stderr_output))\n\u001b[0;32m   2033\u001b[0m \u001b[39melif\u001b[39;00m stderr_output:\n\u001b[0;32m   2034\u001b[0m     \u001b[39mprint\u001b[39m(stderr_output)\n",
      "\u001b[1;31mInvocationException\u001b[0m: Program terminated with status: 1. stderr follows: Format: \"jpg\" not recognized. Use one of:\r\n"
     ]
    }
   ],
   "source": [
    "# 의사결정나무 시각화\n",
    "\n",
    "dot_data = export_graphviz(model, out_file=None,\n",
    "                           feature_names=x_train.columns,\n",
    "                           class_names=model.classes_,\n",
    "                           filled=True, rounded=True,\n",
    "                           special_characters=True)\n",
    "dot_data\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "\n",
    "Image(graph.create_jpg())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image-12.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6976744186046512\n",
      "0.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hamin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "### 랜덤포레스트 모델 생성 \n",
    "\n",
    "# 기본 모델 \n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=234,\n",
    "                            bootstrap=True,class_weight=None,criterion='gini',\n",
    "                            max_leaf_nodes=None,max_features=5,\n",
    "                            min_impurity_decrease=0.0, min_samples_leaf=1,\n",
    "                            min_samples_split=2,min_weight_fraction_leaf=0.0,\n",
    "                            n_jobs=None, oob_score=False, verbose=0)\n",
    "\n",
    "rf.fit(x_train,y_train)\n",
    "\n",
    "y_train_pred = rf.predict(x_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "\n",
    "# 정확도 계산 \n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(accuracy_score(y_train,y_train_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 검증데이터 정확도 높아졌지만 여전히 차이 많이 남 \n",
    "\n",
    "걍 데이터 떄문이라고 생각하고 ㄱㄱ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.81      0.71        31\n",
      "           2       0.60      0.60      0.60        25\n",
      "           3       0.67      0.29      0.40         7\n",
      "           5       1.00      0.67      0.80         6\n",
      "           6       1.00      0.50      0.67         4\n",
      "           7       0.92      0.92      0.92        13\n",
      "\n",
      "    accuracy                           0.70        86\n",
      "   macro avg       0.81      0.63      0.68        86\n",
      "weighted avg       0.72      0.70      0.69        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 랜덤포레스트 \n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Al    0.245357\n",
       "Mg    0.158151\n",
       "Ba    0.138425\n",
       "Ca    0.114311\n",
       "RI    0.104349\n",
       "Na    0.080382\n",
       "K     0.067753\n",
       "Si    0.059174\n",
       "Fe    0.032099\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤포레스트 변수 중요도 확인\n",
    "feature_imp = pd.Series(rf.feature_importances_,index=x_train.columns).sort_values(ascending=False)\n",
    "feature_imp[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hamin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\Hamin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\Hamin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 랜덤포레스트 변수 중요도 시각와\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=feature_imp,y=feature_imp.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. n_estimators:\n",
    "\n",
    "- 의사결정 트리의 개수를 지정합니다.\n",
    "- 일반적으로 더 많은 트리를 사용하면 모델의 성능이 향상됩니다. 하지만 계산 비용도 증가하므로 적절한 값을 선택해야 합니다.\n",
    "2. criterion:\n",
    "\n",
    "- 노드 분할 기준을 선택합니다. 'gini'나 'entropy' 중 하나를 선택합니다.\n",
    "- 기본값은 'gini'입니다.\n",
    "\n",
    "3. max_depth:\n",
    "\n",
    "- 각 의사결정 트리의 최대 깊이를 제한합니다.\n",
    "- 깊이를 제한하여 과적합을 방지하거나 모델을 간단하게 만들 수 있습니다.\n",
    "4. min_samples_split:\n",
    "\n",
    "- 노드를 분할하기 위한 최소 샘플 수를 지정합니다.\n",
    "- 이 값보다 적은 수의 샘플이 노드에 있으면 더 이상 분할하지 않습니다.\n",
    "\n",
    "5. min_samples_leaf:\n",
    "\n",
    "- 리프 노드(말단 노드)에 있어야 하는 최소 샘플 수를 지정합니다.\n",
    "- 이 값보다 적은 수의 샘플이 있는 리프 노드는 더 이상 분할하지 않습니다.\n",
    "\n",
    "6. max_features:\n",
    "\n",
    "- 각 트리에서 분할할 때 고려할 최대 특성(속성)의 수를 지정합니다.\n",
    "- 작은 값으로 설정하면 모델의 다양성이 증가하고 과적합을 방지할 수 있습니다.\n",
    "7. bootstrap:\n",
    "\n",
    "- 데이터를 무작위로 복원 추출(bootstrap 샘플링)하여 각 트리를 학습할지 여부를 지정합니다.\n",
    "- 기본값은 True이며, True로 설정하면 무작위 샘플링을 수행합니다.\n",
    "8. n_jobs:\n",
    "\n",
    "- 병렬 처리를 위해 사용할 CPU 코어의 수를 지정합니다.\n",
    "-1로 설정하면 가능한 모든 코어를 사용합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 내생각\n",
    "\n",
    "파라미터를 근데 내가 정하는게 의미가 있나...싶은 생각이 들었음.\n",
    "데이터에 대한 인사이트가 아니라 그냥 분류나 회귀를 위한 모델링을 하기위한 파라미터를 정의하는데 이거는 사이킷 런이 알아서 해줌\n",
    "목적은 분류나 회귀를 잘하는 모델을 만드는거라 파라미터 튜닝을 내가 할 필요는 없음\n",
    "그래서 그리드서치, 랜덤서치, 베이지안 최적화 등등을 하는거 같음\n",
    "\n",
    "원래 파라미터 하나마다 내가 설정할만한건줄 알았는데 그런느낌은 아닌듯 ㅋ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
